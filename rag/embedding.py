# rag/embedding.py

from sentence_transformers import SentenceTransformer
from typing import List

# Choix du mod√®le performant pour le fran√ßais m√©dical
MODEL_NAME = "dangvantuan/sentence-camembert-base"

# Variable globale pour stocker le mod√®le en m√©moire (Lazy Loading)
_model = None

def get_embedding_model():
    """
    Charge le mod√®le d'embedding s'il n'est pas d√©j√† charg√©.
    """
    global _model
    if _model is None:
        print(f"üß† Chargement du mod√®le d'embedding : {MODEL_NAME}...")
        _model = SentenceTransformer(MODEL_NAME)
        print("‚úÖ Mod√®le charg√© avec succ√®s !")
    return _model

def embed_text(text: str) -> List[float]:
    """
    Convertit un seul texte simple en vecteur (embedding).
    """
    model = get_embedding_model()
    # encode() renvoie un tableau numpy, on le convertit en liste python standard
    embedding = model.encode(text)
    return embedding.tolist()

def embed_batch(texts: List[str]) -> List[List[float]]:
    """
    Convertit une liste de textes en vecteurs (id√©al pour le chunking).
    Affiche une barre de progression.
    """
    model = get_embedding_model()
    embeddings = model.encode(texts, show_progress_bar=True)
    return embeddings.tolist()